{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bf44f8b-967f-4be6-9c90-79c19f59dcec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "\n",
    "from pipeline_vsdi import cleaning as cl\n",
    "from pipeline_vsdi.embedding import autoencoder as ae\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "073f2396-dc0e-491a-aca6-d8a9b00e5ff9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PATHS AND PARAMETERS\n",
    "DATA_PATH = Path('/Volumes/imaging1/davide/ATC_Data_preprocessed')\n",
    "OUTPUT_BASE_PATH = Path('/Users/davide/Dropbox/Projects/ATC/autoencoders')\n",
    "\n",
    "MODEL_PATH = OUTPUT_BASE_PATH.joinpath('models')\n",
    "\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "save_model = True\n",
    "save_history = True\n",
    "\n",
    "# Initialize variables\n",
    "animals = ['A04', 'A06', 'A07', 'A08']\n",
    "days = ['Day1','Day3','Day5','Day7']\n",
    "\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "N_EPOCHS = 1\n",
    "LEARNING_RATE = pow(10,-4)\n",
    "\n",
    "LATENT_DIM = 10\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01c87dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING AUTOENCODER FOR ANIMAL: A04, DAY Day1\n",
      "Preporcessing data ... \n",
      "Starting training job ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, batch loss: 0.0176: 100%|██████████| 188/188 [09:54<00:00,  3.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \t\t Training Loss: 0.021938336993310045 \t\t Validation Loss: 0.08375311531919113\n",
      "Done.\n",
      "TRAINING AUTOENCODER FOR ANIMAL: A04, DAY Day3\n"
     ]
    }
   ],
   "source": [
    "for animal,day in product(animals,days):\n",
    "\n",
    "    print(f'TRAINING AUTOENCODER FOR ANIMAL: {animal}, DAY {day}')\n",
    "\n",
    "\n",
    "    # load data\n",
    "    vsdi1 = loadmat(DATA_PATH.joinpath(f'{animal}/{day}/vsdi_ATC1.mat'))['vsdi_data']\n",
    "    vsdi2 = loadmat(DATA_PATH.joinpath(f'{animal}/{day}/vsdi_ATC2.mat'))['vsdi_data']\n",
    "    mask = loadmat(DATA_PATH.joinpath(f'{animal}/{day}/vsdi_mask.mat'))['mask']\n",
    "\n",
    "    # prepare data\n",
    "    X = np.concatenate([vsdi1,vsdi2],axis=-1)\n",
    "    \n",
    "    # clear memory\n",
    "    del vsdi1\n",
    "    del vsdi2\n",
    "\n",
    "    # concatenate sessions\n",
    "\n",
    "    print('Preporcessing data ... ')\n",
    "\n",
    "    X = cl.clean_outliers(X)\n",
    "    # reshape in (n_sapmples,n_channels,n_pixels,n_pixels) format\n",
    "    X = np.transpose(X,(2,0,1))\n",
    "    X = X[:,np.newaxis,:,:]\n",
    "    # scale each imahe independently betw. 0 and 1\n",
    "    d = np.max(X,axis=(1,2,3))[:, np.newaxis, np.newaxis, np.newaxis] - np.min(X,axis=(1,2,3))[:, np.newaxis, np.newaxis, np.newaxis]\n",
    "    X = (X - np.min(X,axis=(1,2,3))[:, np.newaxis, np.newaxis, np.newaxis]) / d\n",
    "\n",
    "    train_size = 80*X.shape[0]//100\n",
    "    valid_size = X.shape[0] - train_size\n",
    "    train, valid = random_split(X,[train_size,valid_size])\n",
    "    trainloader = DataLoader(train, batch_size=BATCH_SIZE)\n",
    "    validloader = DataLoader(valid, batch_size=BATCH_SIZE)\n",
    "\n",
    "    h = X.shape[-1]\n",
    "    w = X.shape[-2]\n",
    "    \n",
    "    # model definition and compliation\n",
    "    model = ae.Conv_AE(LATENT_DIM,h_pixels=h,w_pixels=w)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=pow(10,-4), weight_decay=0)\n",
    "\n",
    "    print('Starting training job ...')\n",
    "\n",
    "    history = ae.train_autoencoder(model,trainloader,\n",
    "                            validloader=validloader,\n",
    "                            epochs = N_EPOCHS)\n",
    "    \n",
    "    if save_history:\n",
    "        history_path = MODEL_PATH.joinpath(f'history_{animal}_day.pickle')\n",
    "        with open(history_path, \"wb\") as file:\n",
    "            pickle.dump(history, file)\n",
    "\n",
    "\n",
    "    if save_model:\n",
    "        torch.save(model,MODEL_PATH.joinpath(f'animal_{animal}_day{day}'))\n",
    "\n",
    "    \n",
    "    print('Done.')\n",
    "\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7473ef40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipeline_vsdi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
